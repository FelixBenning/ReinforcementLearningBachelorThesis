\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\babel@toc {english}{}
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{Introduction}{vii}{chapter*.3}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {1}Markov Decision Processes}{1}{chapter.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {1.1}Introduction}{1}{section.1.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {1.2}Model Formulation}{4}{section.1.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {1.2.1}Outlook}{10}{subsection.1.2.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {1.3}Fixed Point Equations for Value Functions}{11}{section.1.3}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {1.4}Optimal Value Functions}{15}{section.1.4}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {1.4.1}Finite Outmatching}{15}{subsection.1.4.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {1.4.2}Fix-Point Equations for Optimal Value functions}{17}{subsection.1.4.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {1.5}Optimal policies}{23}{section.1.5}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {1.6}Dynamic Programming}{30}{section.1.6}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {1.6.1}Bootstrapping and Discounting}{33}{subsection.1.6.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {2}Reinforcement Learning Algorithms}{35}{chapter.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.1}Introduction}{35}{section.2.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.1.1}Naive Batch Learning}{36}{subsection.2.1.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.2}Monte Carlo}{37}{section.2.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.2.1}From \(\pi \) to \(\pi ^*\)}{38}{subsection.2.2.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.2.2}Shortcomings of Monte Carlo}{42}{subsection.2.2.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.3}Temporal Difference Learning TD}{43}{section.2.3}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.3.1}Shortcomings of TD}{45}{subsection.2.3.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.4}Growing Batch Learning}{46}{section.2.4}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.5}TD(\(\lambda \)) -- Mixing Monte Carlo and TD}{48}{section.2.5}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.5.1}\(n\)-Step Return}{48}{subsection.2.5.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.5.2}TD(\(\lambda \)) Forward View - \(\lambda \)-return}{49}{subsection.2.5.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.5.3}TD(\(\lambda \)) Backward View}{51}{subsection.2.5.3}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.5.4}Variations - True Online TD(\(\lambda )\)}{54}{subsection.2.5.4}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.6}Q-learning}{55}{section.2.6}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.6.1}Shortcomings of Q-learning}{55}{subsection.2.6.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.7}Exploration}{56}{section.2.7}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.7.1}Optimism}{56}{subsection.2.7.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.7.2}Boltzmann Exploration}{57}{subsection.2.7.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.7.3}Directed Exploration}{57}{subsection.2.7.3}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{Interval Estimation}{58}{section*.10}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{Bayesian Exploration}{59}{section*.11}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.7.4}Intrinsic Rewards}{59}{subsection.2.7.4}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{Curiosity-Driven Exploration}{60}{section*.12}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.8}Function Approximation}{62}{section.2.8}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.8.1}Mean Squared Value Error}{64}{subsection.2.8.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.8.2}Very Short Introduction to Gradient Decent}{65}{subsection.2.8.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.8.3}A counterexample}{66}{subsection.2.8.3}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {3}Stochastic Approximation -- Convergence}{69}{chapter.3}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.1}Introduction}{69}{section.3.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.2}Learning Rates}{70}{section.3.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.3}Application to Reinforcement Learning}{73}{section.3.3}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.4}Proof of Theorem \ref {JAAKKOLA:THM}}{79}{section.3.4}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {A}Appendix}{93}{appendix.A}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {A.1}Probability Theory}{93}{section.A.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {A.2}Analysis}{97}{section.A.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {A.3}Autoencoder}{98}{section.A.3}% 
